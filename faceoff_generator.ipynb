{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 103\n"
     ]
    }
   ],
   "source": [
    "from prepare_data_generator import prepare_data\n",
    "\n",
    "import random\n",
    "seed = 32\n",
    "validation_split = 0.2\n",
    "\n",
    "def shuffle_and_split(data, validation_split, seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    random.shuffle(data)\n",
    "    random.seed()\n",
    "    split = int(len(data)*(1-validation_split))\n",
    "    return data[:split], data[split:]\n",
    "\n",
    "face_landmarks_dict = {'train': {}, 'val': {}}\n",
    "face_landmarks_final = {'train': [], 'val': []}\n",
    "# load muct clm data through https://github.com/azhongwl/clmtools; around 600 faces, ~100 in the wild of varying poses\n",
    "landmarks = prepare_data('/Users/azhong/face/data/muct_clmtools/images/',\n",
    "                         '/Users/azhong/face/data/muct_clmtools/annotations.csv',\n",
    "                         'muct_clmtools')\n",
    "face_landmarks_dict['train']['muct_clmtools'], face_landmarks_dict['val']['muct_clmtools'] = shuffle_and_split(\n",
    "    landmarks, validation_split, seed)\n",
    "for train_val in ['train', 'val']:\n",
    "    for key in face_landmarks_dict[train_val].keys():\n",
    "        face_landmarks_final[train_val].extend(face_landmarks_dict[train_val][key])\n",
    "for train_val in ['train', 'val']:\n",
    "    for fl in face_landmarks_final[train_val]:\n",
    "        fl.convert_to_landmark_type('muct')\n",
    "print(len(face_landmarks_final['train']), len(face_landmarks_final['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 307.0926 - mean_squared_error: 307.0926 - val_loss: 277.8309 - val_mean_squared_error: 277.8309\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 277.83094, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.01-277.83-307.09.hdf5\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 292.8306 - mean_squared_error: 292.8306 - val_loss: 246.3484 - val_mean_squared_error: 246.3484\n",
      "\n",
      "Epoch 00002: val_loss improved from 277.83094 to 246.34844, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.02-246.35-292.83.hdf5\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 243.9644 - mean_squared_error: 243.9644 - val_loss: 156.0134 - val_mean_squared_error: 156.0134\n",
      "\n",
      "Epoch 00003: val_loss improved from 246.34844 to 156.01339, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.03-156.01-243.96.hdf5\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 1s 302ms/step - loss: 137.5107 - mean_squared_error: 137.5107 - val_loss: 34.1899 - val_mean_squared_error: 34.1899\n",
      "\n",
      "Epoch 00004: val_loss improved from 156.01339 to 34.18986, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.04-34.19-134.61.hdf5\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 1s 496ms/step - loss: 82.3363 - mean_squared_error: 82.3363 - val_loss: 103.0621 - val_mean_squared_error: 103.0621\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 1s 345ms/step - loss: 63.4907 - mean_squared_error: 63.4907 - val_loss: 11.1407 - val_mean_squared_error: 11.1407\n",
      "\n",
      "Epoch 00006: val_loss improved from 34.18986 to 11.14065, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.06-11.14-63.49.hdf5\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 1s 309ms/step - loss: 39.1718 - mean_squared_error: 39.1718 - val_loss: 27.6329 - val_mean_squared_error: 27.6329\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 52.6488 - mean_squared_error: 52.6488 - val_loss: 30.7322 - val_mean_squared_error: 30.7322\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 46.9156 - mean_squared_error: 46.9156 - val_loss: 17.2459 - val_mean_squared_error: 17.2459\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 39.7748 - mean_squared_error: 39.7748 - val_loss: 24.7855 - val_mean_squared_error: 24.7855\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 40.0489 - mean_squared_error: 40.0489 - val_loss: 16.1739 - val_mean_squared_error: 16.1739\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 1s 314ms/step - loss: 28.1780 - mean_squared_error: 28.1780 - val_loss: 9.0631 - val_mean_squared_error: 9.0631\n",
      "\n",
      "Epoch 00012: val_loss improved from 11.14065 to 9.06306, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.12-9.06-28.18.hdf5\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 1s 340ms/step - loss: 26.3645 - mean_squared_error: 26.3645 - val_loss: 10.1344 - val_mean_squared_error: 10.1344\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 31.1467 - mean_squared_error: 31.1467 - val_loss: 9.7585 - val_mean_squared_error: 9.7585\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 28.3287 - mean_squared_error: 28.3287 - val_loss: 12.5988 - val_mean_squared_error: 12.5988\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 1s 347ms/step - loss: 29.9077 - mean_squared_error: 29.9077 - val_loss: 13.2762 - val_mean_squared_error: 13.2762\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 1s 308ms/step - loss: 27.1779 - mean_squared_error: 27.1779 - val_loss: 9.1395 - val_mean_squared_error: 9.1395\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 31.6943 - mean_squared_error: 31.6943 - val_loss: 8.7537 - val_mean_squared_error: 8.7537\n",
      "\n",
      "Epoch 00018: val_loss improved from 9.06306 to 8.75366, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.18-8.75-31.69.hdf5\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 27.1130 - mean_squared_error: 27.1130 - val_loss: 8.6963 - val_mean_squared_error: 8.6963\n",
      "\n",
      "Epoch 00019: val_loss improved from 8.75366 to 8.69628, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.19-8.70-27.11.hdf5\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 25.9582 - mean_squared_error: 25.9582 - val_loss: 9.6627 - val_mean_squared_error: 9.6627\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 1s 308ms/step - loss: 25.2954 - mean_squared_error: 25.2954 - val_loss: 10.4471 - val_mean_squared_error: 10.4471\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 1s 438ms/step - loss: 27.3495 - mean_squared_error: 27.3495 - val_loss: 9.1494 - val_mean_squared_error: 9.1494\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 27.0531 - mean_squared_error: 27.0531 - val_loss: 8.7070 - val_mean_squared_error: 8.7070\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 26.8286 - mean_squared_error: 26.8286 - val_loss: 8.6984 - val_mean_squared_error: 8.6984\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 1s 315ms/step - loss: 23.8897 - mean_squared_error: 23.8897 - val_loss: 12.8359 - val_mean_squared_error: 12.8359\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 32.9080 - mean_squared_error: 32.9080 - val_loss: 10.6211 - val_mean_squared_error: 10.6211\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 29.8538 - mean_squared_error: 29.8538 - val_loss: 8.6853 - val_mean_squared_error: 8.6853\n",
      "\n",
      "Epoch 00027: val_loss improved from 8.69628 to 8.68532, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.27-8.69-29.61.hdf5\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 1s 347ms/step - loss: 26.3947 - mean_squared_error: 26.3947 - val_loss: 8.6870 - val_mean_squared_error: 8.6870\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 26.5293 - mean_squared_error: 26.5293"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1e72d025074c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     validation_data = val_data_gen.flow(face_landmarks_final['val'], MUCT[topic], (32, 32), batch_size))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2249\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m   2252\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from generator import ImageFaceLandmarkDataGenerator\n",
    "from muct import MUCT\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image / 255.0\n",
    "    image = image - 0.5\n",
    "    image = image * 2.0\n",
    "    return image\n",
    "\n",
    "\n",
    "train_data_gen = ImageFaceLandmarkDataGenerator(rotate_bounding_box_part='face',\n",
    "                                                rotate_limit_in_degrees=10,\n",
    "                                                scale_bounding_box_part='face',\n",
    "                                                scale_bounding_box_size=64,\n",
    "                                                scale_limit_ratio=0.1,\n",
    "                                                translate_x_ratio=0.2,\n",
    "                                                translate_y_ratio=0.3,\n",
    "                                                target_bounding_box_part='mouth',\n",
    "                                                preprocessing_function=preprocess_image)\n",
    "val_data_gen = ImageFaceLandmarkDataGenerator(rotate_bounding_box_part='face',\n",
    "                                              scale_bounding_box_part='face',\n",
    "                                              scale_bounding_box_size=64,\n",
    "                                              target_bounding_box_part='mouth',\n",
    "                                              preprocessing_function=preprocess_image)\n",
    "                                              \n",
    "batch_size = 32\n",
    "input_shape = (32, 32, 3)\n",
    "topic = 'mouth_12'\n",
    "output_size = int(topic.split('_')[-1])\n",
    "num_epochs = 1000\n",
    "patience = 50\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "model_name = 'kao_onet_{}_lm_{}'.format(input_shape[0], output_size)\n",
    "\n",
    "base_path = 'models/' + model_name + '_'\n",
    "base_path += now.strftime(\"%Y_%m_%d_%H_%M_%S\") + '/'\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "\n",
    "from models import Kao_Onet\n",
    "model = Kao_Onet(input_shape, output_size)\n",
    "model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])\n",
    "\n",
    "log_file_path = base_path + 'faceoff_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                              patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + 'faceoff_' + model_name\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_loss:.2f}-{loss:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                   save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "\n",
    "model.fit_generator(train_data_gen.flow(face_landmarks_final['train'], MUCT[topic], (32, 32), batch_size),\n",
    "                    steps_per_epoch = 3,\n",
    "                    epochs = num_epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1,\n",
    "                    validation_data = val_data_gen.flow(face_landmarks_final['val'], MUCT[topic], (32, 32), batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
