{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 103\n"
     ]
    }
   ],
   "source": [
    "from prepare_data_generator import prepare_data\n",
    "\n",
    "import random\n",
    "seed = 32\n",
    "validation_split = 0.2\n",
    "\n",
    "def shuffle_and_split(data, validation_split, seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    random.shuffle(data)\n",
    "    random.seed()\n",
    "    split = int(len(data)*(1-validation_split))\n",
    "    return data[:split], data[split:]\n",
    "\n",
    "face_landmarks_dict = {'train': {}, 'val': {}}\n",
    "face_landmarks_final = {'train': [], 'val': []}\n",
    "# load muct clm data through https://github.com/azhongwl/clmtools; around 600 faces, ~100 in the wild of varying poses\n",
    "landmarks = prepare_data('/Users/azhong/face/data/muct_clmtools/images/',\n",
    "                         '/Users/azhong/face/data/muct_clmtools/annotations.csv',\n",
    "                         'muct_clmtools')\n",
    "face_landmarks_dict['train']['muct_clmtools'], face_landmarks_dict['val']['muct_clmtools'] = shuffle_and_split(\n",
    "    landmarks, validation_split, seed)\n",
    "for train_val in ['train', 'val']:\n",
    "    for key in face_landmarks_dict[train_val].keys():\n",
    "        face_landmarks_final[train_val].extend(face_landmarks_dict[train_val][key])\n",
    "for train_val in ['train', 'val']:\n",
    "    for fl in face_landmarks_final[train_val]:\n",
    "        fl.convert_to_landmark_type('muct')\n",
    "print(len(face_landmarks_final['train']), len(face_landmarks_final['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 307.0926 - mean_squared_error: 307.0926 - val_loss: 277.8309 - val_mean_squared_error: 277.8309\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 277.83094, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.01-277.83-307.09.hdf5\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 292.8306 - mean_squared_error: 292.8306 - val_loss: 246.3484 - val_mean_squared_error: 246.3484\n",
      "\n",
      "Epoch 00002: val_loss improved from 277.83094 to 246.34844, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.02-246.35-292.83.hdf5\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 243.9644 - mean_squared_error: 243.9644 - val_loss: 156.0134 - val_mean_squared_error: 156.0134\n",
      "\n",
      "Epoch 00003: val_loss improved from 246.34844 to 156.01339, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.03-156.01-243.96.hdf5\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 1s 302ms/step - loss: 137.5107 - mean_squared_error: 137.5107 - val_loss: 34.1899 - val_mean_squared_error: 34.1899\n",
      "\n",
      "Epoch 00004: val_loss improved from 156.01339 to 34.18986, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.04-34.19-134.61.hdf5\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 1s 496ms/step - loss: 82.3363 - mean_squared_error: 82.3363 - val_loss: 103.0621 - val_mean_squared_error: 103.0621\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 1s 345ms/step - loss: 63.4907 - mean_squared_error: 63.4907 - val_loss: 11.1407 - val_mean_squared_error: 11.1407\n",
      "\n",
      "Epoch 00006: val_loss improved from 34.18986 to 11.14065, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.06-11.14-63.49.hdf5\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 1s 309ms/step - loss: 39.1718 - mean_squared_error: 39.1718 - val_loss: 27.6329 - val_mean_squared_error: 27.6329\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 52.6488 - mean_squared_error: 52.6488 - val_loss: 30.7322 - val_mean_squared_error: 30.7322\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 46.9156 - mean_squared_error: 46.9156 - val_loss: 17.2459 - val_mean_squared_error: 17.2459\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 39.7748 - mean_squared_error: 39.7748 - val_loss: 24.7855 - val_mean_squared_error: 24.7855\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 40.0489 - mean_squared_error: 40.0489 - val_loss: 16.1739 - val_mean_squared_error: 16.1739\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 1s 314ms/step - loss: 28.1780 - mean_squared_error: 28.1780 - val_loss: 9.0631 - val_mean_squared_error: 9.0631\n",
      "\n",
      "Epoch 00012: val_loss improved from 11.14065 to 9.06306, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.12-9.06-28.18.hdf5\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 1s 340ms/step - loss: 26.3645 - mean_squared_error: 26.3645 - val_loss: 10.1344 - val_mean_squared_error: 10.1344\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 31.1467 - mean_squared_error: 31.1467 - val_loss: 9.7585 - val_mean_squared_error: 9.7585\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 28.3287 - mean_squared_error: 28.3287 - val_loss: 12.5988 - val_mean_squared_error: 12.5988\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 1s 347ms/step - loss: 29.9077 - mean_squared_error: 29.9077 - val_loss: 13.2762 - val_mean_squared_error: 13.2762\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 1s 308ms/step - loss: 27.1779 - mean_squared_error: 27.1779 - val_loss: 9.1395 - val_mean_squared_error: 9.1395\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 31.6943 - mean_squared_error: 31.6943 - val_loss: 8.7537 - val_mean_squared_error: 8.7537\n",
      "\n",
      "Epoch 00018: val_loss improved from 9.06306 to 8.75366, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.18-8.75-31.69.hdf5\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 27.1130 - mean_squared_error: 27.1130 - val_loss: 8.6963 - val_mean_squared_error: 8.6963\n",
      "\n",
      "Epoch 00019: val_loss improved from 8.75366 to 8.69628, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.19-8.70-27.11.hdf5\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 25.9582 - mean_squared_error: 25.9582 - val_loss: 9.6627 - val_mean_squared_error: 9.6627\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 1s 308ms/step - loss: 25.2954 - mean_squared_error: 25.2954 - val_loss: 10.4471 - val_mean_squared_error: 10.4471\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 1s 438ms/step - loss: 27.3495 - mean_squared_error: 27.3495 - val_loss: 9.1494 - val_mean_squared_error: 9.1494\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 27.0531 - mean_squared_error: 27.0531 - val_loss: 8.7070 - val_mean_squared_error: 8.7070\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 26.8286 - mean_squared_error: 26.8286 - val_loss: 8.6984 - val_mean_squared_error: 8.6984\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 1s 315ms/step - loss: 23.8897 - mean_squared_error: 23.8897 - val_loss: 12.8359 - val_mean_squared_error: 12.8359\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 32.9080 - mean_squared_error: 32.9080 - val_loss: 10.6211 - val_mean_squared_error: 10.6211\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 29.8538 - mean_squared_error: 29.8538 - val_loss: 8.6853 - val_mean_squared_error: 8.6853\n",
      "\n",
      "Epoch 00027: val_loss improved from 8.69628 to 8.68532, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.27-8.69-29.61.hdf5\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 1s 347ms/step - loss: 26.3947 - mean_squared_error: 26.3947 - val_loss: 8.6870 - val_mean_squared_error: 8.6870\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 26.5293 - mean_squared_error: 26.5293"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1e72d025074c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     validation_data = val_data_gen.flow(face_landmarks_final['val'], MUCT[topic], (32, 32), batch_size))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2249\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m   2252\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from generator import ImageFaceLandmarkDataGenerator\n",
    "from muct import MUCT\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image / 255.0\n",
    "    image = image - 0.5\n",
    "    image = image * 2.0\n",
    "    return image\n",
    "\n",
    "\n",
    "train_data_gen = ImageFaceLandmarkDataGenerator(rotate_bounding_box_part='face',\n",
    "                                                rotate_limit_in_degrees=10,\n",
    "                                                scale_bounding_box_part='face',\n",
    "                                                scale_bounding_box_size=64,\n",
    "                                                scale_limit_ratio=0.1,\n",
    "                                                translate_x_ratio=0.2,\n",
    "                                                translate_y_ratio=0.3,\n",
    "                                                target_bounding_box_part='mouth',\n",
    "                                                preprocessing_function=preprocess_image)\n",
    "val_data_gen = ImageFaceLandmarkDataGenerator(rotate_bounding_box_part='face',\n",
    "                                              scale_bounding_box_part='face',\n",
    "                                              scale_bounding_box_size=64,\n",
    "                                              target_bounding_box_part='mouth',\n",
    "                                              preprocessing_function=preprocess_image)\n",
    "                                              \n",
    "batch_size = 32\n",
    "input_shape = (32, 32, 3)\n",
    "topic = 'mouth_12'\n",
    "output_size = int(topic.split('_')[-1])\n",
    "num_epochs = 1000\n",
    "patience = 50\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "model_name = 'kao_onet_{}_lm_{}'.format(input_shape[0], output_size)\n",
    "\n",
    "base_path = 'models/' + model_name + '_'\n",
    "base_path += now.strftime(\"%Y_%m_%d_%H_%M_%S\") + '/'\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "\n",
    "from models import Kao_Onet\n",
    "model = Kao_Onet(input_shape, output_size)\n",
    "model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])\n",
    "\n",
    "log_file_path = base_path + 'faceoff_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                              patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + 'faceoff_' + model_name\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_loss:.2f}-{loss:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                   save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "\n",
    "model.fit_generator(train_data_gen.flow(face_landmarks_final['train'], MUCT[topic], (32, 32), batch_size),\n",
    "                    steps_per_epoch = 3,\n",
    "                    epochs = num_epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1,\n",
    "                    validation_data = val_data_gen.flow(face_landmarks_final['val'], MUCT[topic], (32, 32), batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from generator import ImageFaceLandmarkDataGenerator\n",
    "from muct import MUCT\n",
    "\n",
    "batch_size = 32\n",
    "input_shape = (32, 32, 3)\n",
    "topic = 'mouth_12'\n",
    "output_size = int(topic.split('_')[-1])\n",
    "\n",
    "test_generator = ImageFaceLandmarkDataGenerator(rotate_bounding_box_part='face',\n",
    "                                                rotate_limit_in_degrees=10,\n",
    "                                                scale_bounding_box_part='face',\n",
    "                                                scale_bounding_box_size=64,\n",
    "                                                scale_limit_ratio=0.1,\n",
    "                                                translate_x_ratio=0.2,\n",
    "                                                translate_y_ratio=0.3,\n",
    "                                                target_bounding_box_part='mouth')\n",
    "\n",
    "for X, y in test_generator.flow(face_landmarks_final['train'], MUCT[topic], (32, 32), batch_size):\n",
    "    bgr_image = X[0]\n",
    "    landmarks = y[0]\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "    for i in range(0, len(landmarks), 2):\n",
    "        cv2.circle(rgb_image, (int(landmarks[i]), int(landmarks[i+1])), 1, (255), -1)\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
