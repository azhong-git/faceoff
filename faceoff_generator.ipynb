{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 103\n"
     ]
    }
   ],
   "source": [
    "from prepare_data_generator import prepare_data\n",
    "\n",
    "import random\n",
    "seed = 32\n",
    "validation_split = 0.2\n",
    "\n",
    "def shuffle_and_split(data, validation_split, seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    random.shuffle(data)\n",
    "    random.seed()\n",
    "    split = int(len(data)*(1-validation_split))\n",
    "    return data[:split], data[split:]\n",
    "\n",
    "face_landmarks_dict = {'train': {}, 'val': {}}\n",
    "face_landmarks_final = {'train': [], 'val': []}\n",
    "# load muct clm data through https://github.com/azhongwl/clmtools; around 600 faces, ~100 in the wild of varying poses\n",
    "landmarks = prepare_data('/data/muct_clmtools/images/',\n",
    "                         '/data/muct_clmtools/annotations.csv',\n",
    "                         'muct_clmtools')\n",
    "face_landmarks_dict['train']['muct_clmtools'], face_landmarks_dict['val']['muct_clmtools'] = shuffle_and_split(\n",
    "    landmarks, validation_split, seed)\n",
    "for train_val in ['train', 'val']:\n",
    "    for key in face_landmarks_dict[train_val].keys():\n",
    "        face_landmarks_final[train_val].extend(face_landmarks_dict[train_val][key])\n",
    "for train_val in ['train', 'val']:\n",
    "    for fl in face_landmarks_final[train_val]:\n",
    "        fl.convert_to_landmark_type('muct')\n",
    "print(len(face_landmarks_final['train']), len(face_landmarks_final['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 307.0926 - mean_squared_error: 307.0926 - val_loss: 277.8309 - val_mean_squared_error: 277.8309\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 277.83094, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.01-277.83-307.09.hdf5\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 292.8306 - mean_squared_error: 292.8306 - val_loss: 246.3484 - val_mean_squared_error: 246.3484\n",
      "\n",
      "Epoch 00002: val_loss improved from 277.83094 to 246.34844, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.02-246.35-292.83.hdf5\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 243.9644 - mean_squared_error: 243.9644 - val_loss: 156.0134 - val_mean_squared_error: 156.0134\n",
      "\n",
      "Epoch 00003: val_loss improved from 246.34844 to 156.01339, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.03-156.01-243.96.hdf5\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 1s 302ms/step - loss: 137.5107 - mean_squared_error: 137.5107 - val_loss: 34.1899 - val_mean_squared_error: 34.1899\n",
      "\n",
      "Epoch 00004: val_loss improved from 156.01339 to 34.18986, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.04-34.19-134.61.hdf5\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 1s 496ms/step - loss: 82.3363 - mean_squared_error: 82.3363 - val_loss: 103.0621 - val_mean_squared_error: 103.0621\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 1s 345ms/step - loss: 63.4907 - mean_squared_error: 63.4907 - val_loss: 11.1407 - val_mean_squared_error: 11.1407\n",
      "\n",
      "Epoch 00006: val_loss improved from 34.18986 to 11.14065, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.06-11.14-63.49.hdf5\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 1s 309ms/step - loss: 39.1718 - mean_squared_error: 39.1718 - val_loss: 27.6329 - val_mean_squared_error: 27.6329\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 52.6488 - mean_squared_error: 52.6488 - val_loss: 30.7322 - val_mean_squared_error: 30.7322\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 46.9156 - mean_squared_error: 46.9156 - val_loss: 17.2459 - val_mean_squared_error: 17.2459\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 39.7748 - mean_squared_error: 39.7748 - val_loss: 24.7855 - val_mean_squared_error: 24.7855\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 40.0489 - mean_squared_error: 40.0489 - val_loss: 16.1739 - val_mean_squared_error: 16.1739\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 1s 314ms/step - loss: 28.1780 - mean_squared_error: 28.1780 - val_loss: 9.0631 - val_mean_squared_error: 9.0631\n",
      "\n",
      "Epoch 00012: val_loss improved from 11.14065 to 9.06306, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.12-9.06-28.18.hdf5\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 1s 340ms/step - loss: 26.3645 - mean_squared_error: 26.3645 - val_loss: 10.1344 - val_mean_squared_error: 10.1344\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 31.1467 - mean_squared_error: 31.1467 - val_loss: 9.7585 - val_mean_squared_error: 9.7585\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 28.3287 - mean_squared_error: 28.3287 - val_loss: 12.5988 - val_mean_squared_error: 12.5988\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 1s 347ms/step - loss: 29.9077 - mean_squared_error: 29.9077 - val_loss: 13.2762 - val_mean_squared_error: 13.2762\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 1s 308ms/step - loss: 27.1779 - mean_squared_error: 27.1779 - val_loss: 9.1395 - val_mean_squared_error: 9.1395\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 31.6943 - mean_squared_error: 31.6943 - val_loss: 8.7537 - val_mean_squared_error: 8.7537\n",
      "\n",
      "Epoch 00018: val_loss improved from 9.06306 to 8.75366, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.18-8.75-31.69.hdf5\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 27.1130 - mean_squared_error: 27.1130 - val_loss: 8.6963 - val_mean_squared_error: 8.6963\n",
      "\n",
      "Epoch 00019: val_loss improved from 8.75366 to 8.69628, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.19-8.70-27.11.hdf5\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 25.9582 - mean_squared_error: 25.9582 - val_loss: 9.6627 - val_mean_squared_error: 9.6627\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 1s 308ms/step - loss: 25.2954 - mean_squared_error: 25.2954 - val_loss: 10.4471 - val_mean_squared_error: 10.4471\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 1s 438ms/step - loss: 27.3495 - mean_squared_error: 27.3495 - val_loss: 9.1494 - val_mean_squared_error: 9.1494\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 27.0531 - mean_squared_error: 27.0531 - val_loss: 8.7070 - val_mean_squared_error: 8.7070\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 26.8286 - mean_squared_error: 26.8286 - val_loss: 8.6984 - val_mean_squared_error: 8.6984\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 1s 315ms/step - loss: 23.8897 - mean_squared_error: 23.8897 - val_loss: 12.8359 - val_mean_squared_error: 12.8359\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 32.9080 - mean_squared_error: 32.9080 - val_loss: 10.6211 - val_mean_squared_error: 10.6211\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 29.8538 - mean_squared_error: 29.8538 - val_loss: 8.6853 - val_mean_squared_error: 8.6853\n",
      "\n",
      "Epoch 00027: val_loss improved from 8.69628 to 8.68532, saving model to models/kao_onet_32_lm_12_2018_07_31_14_45_35/faceoff_kao_onet_32_lm_12.27-8.69-29.61.hdf5\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 1s 347ms/step - loss: 26.3947 - mean_squared_error: 26.3947 - val_loss: 8.6870 - val_mean_squared_error: 8.6870\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 26.5293 - mean_squared_error: 26.5293"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1e72d025074c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     validation_data = val_data_gen.flow(face_landmarks_final['val'], MUCT[topic], (32, 32), batch_size))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2249\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m   2252\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from generator import ImageFaceLandmarkDataGenerator\n",
    "from muct import MUCT\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image / 255.0\n",
    "    image = image - 0.5\n",
    "    image = image * 2.0\n",
    "    return image\n",
    "\n",
    "\n",
    "train_data_gen = ImageFaceLandmarkDataGenerator(rotate_bounding_box_part='face',\n",
    "                                                rotate_limit_in_degrees=10,\n",
    "                                                scale_bounding_box_part='face',\n",
    "                                                scale_bounding_box_size=64,\n",
    "                                                scale_limit_ratio=0.1,\n",
    "                                                translate_x_ratio=0.2,\n",
    "                                                translate_y_ratio=0.3,\n",
    "                                                target_bounding_box_part='mouth',\n",
    "                                                preprocessing_function=preprocess_image)\n",
    "val_data_gen = ImageFaceLandmarkDataGenerator(rotate_bounding_box_part='face',\n",
    "                                              scale_bounding_box_part='face',\n",
    "                                              scale_bounding_box_size=64,\n",
    "                                              target_bounding_box_part='mouth',\n",
    "                                              preprocessing_function=preprocess_image)\n",
    "                                              \n",
    "batch_size = 32\n",
    "input_shape = (32, 32, 3)\n",
    "topic = 'mouth_12'\n",
    "output_size = int(topic.split('_')[-1])\n",
    "num_epochs = 1000\n",
    "patience = 50\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "model_name = 'kao_onet_{}_lm_{}'.format(input_shape[0], output_size)\n",
    "\n",
    "base_path = 'models/' + model_name + '_'\n",
    "base_path += now.strftime(\"%Y_%m_%d_%H_%M_%S\") + '/'\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "\n",
    "from models import Kao_Onet\n",
    "model = Kao_Onet(input_shape, output_size)\n",
    "model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])\n",
    "\n",
    "log_file_path = base_path + 'faceoff_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                              patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + 'faceoff_' + model_name\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_loss:.2f}-{loss:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                   save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "\n",
    "model.fit_generator(train_data_gen.flow(face_landmarks_final['train'], MUCT[topic], (32, 32), batch_size),\n",
    "                    steps_per_epoch = 3,\n",
    "                    epochs = num_epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1,\n",
    "                    validation_data = val_data_gen.flow(face_landmarks_final['val'], MUCT[topic], (32, 32), batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 211 255 447\n",
      "12\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHTRJREFUeJztnXusXNd13r91HjNzXxRFUmJoSrJkRXai2tGjjOoiQuo87CpuANlFYdhoDKEwwqCwgDiN2wouULtoC9hFbMFoAxd0JEQOXNlObMOCKzSRhSBC/pFNuXpalS0rci2JIkXxdcl777zO6h8zQkl6f+vO5eWdS2l/P4Dg3LNmn7Nmz1nnzOxv1lrm7hBC5Eex2Q4IITYHBb8QmaLgFyJTFPxCZIqCX4hMUfALkSkKfiEyRcEvRKYo+IXIlGo9g83sFgCfB1AC+BN3/3T0/LIovK7KpC36oaE3DXEgGBPs0IwPbNixABRFetxsq6Zj5totvj9qAczOzX9micaQl7X6uGBgNI7vj8+IBbboPGBE50dki3wMHTkHH4Ho17fpHb706iKOnVye6GjnHPxmVgL4YwDvBvACgO+Z2X3u/gM2pq5KXHbJtqRt2ONB1+91k9uL4ARb6a9QW6vFX/by8jK1zc2kA/nGN++mY266+gpqmwV/zVU9pLay4v7XJCDbFZ+rdslP6HYrfbEGgHaHX/Ra5KJXBheM1uwstdWdNrUZd5HOVbfbp2MGA34OdGbnqc2NX+jL4GLOB/FzwMmL/p3//OcT7349H/tvAvCsuz/n7j0AXwFw6zr2J4SYIusJ/t0Afnra3y+MtwkhXges6zv/JJjZXgB7AaAKPl4KIabLeqLxRQCXn/b3ZeNtZ+Du+9x9j7vvKcPFEiHENFlPNH4PwDVmdpWZtQB8EMB958ctIcRGc84f+919YGa3A/hLjKS+u939qXBM4+h30yv3wyaSSdLXqEhNmm13qK0p+crrTM3HXTSbtu1amKNjimCVt27xYxWenicAKALdqCQ292Dl2PlyeVlyWyhHMh9DEYrvr2pzP7wMlACkX3dZc0fmZ/j70htyhaZp8dV+cgoDAApP73Mw5IOYirEWiXVd3/nd/X4A969nH0KIzUFfwoXIFAW/EJmi4BciUxT8QmSKgl+ITNnwX/idgRlQp2UZX4kScdLXqEG/R8fMtHiSyIljh6mtCiTC7QvpfW5dCCS74PI6dJ5c0gkyBX3Ax51LH4box1eDwYDaipLLSoNBWqpsB1JqWc4E++Ovq98E89Gk/R8G0zToc1nUai7nDQI9zwMfZ8iwbiArzpIEqbW8+7rzC5EpCn4hMkXBL0SmKPiFyBQFvxCZMtXVfisMMyT5wYOMD7ZiWwUrr6dOLlJb2eKJIHNtvsq+e0u6hNNskNBRFHyKi2Bt1kiyBwAUUdkqkohTBclM0bHMuP8eJJGUdXoem4b70e0v8f0VXCWoghJlNZmrMAEmeM0D5+qHLR+jtipQOfqknBsryQYAPfKerUXs0Z1fiExR8AuRKQp+ITJFwS9Epij4hcgUBb8QmTLdxB53+DCd4NAEGkW/l07gqYPOO6EtqBe4fQtPCNq+fUtyu/E8ENSDQIbqRPXxgp1GrciK9Lii5BKmBfeA/jCQtoZ8n4N++n2ug25D7UDairoDDYI6g+wUb8ATbRAkXM0QCXNEMI9RTzSSWBXJdiynai1d0nTnFyJTFPxCZIqCX4hMUfALkSkKfiEyRcEvRKasS+ozs+cBLAIYAhi4+57w+TBUpM7Z8e4pOm771q3J7ScXeRZVJ5CGWhW3/dyWBWqb9bTvrSC7MEjqo62kgFiyibodV2RgWXE5rBnwrD6WnQcAMx2eHdkmdRcjya6qgwzCoM6gB7UE+3Rc0ForyHI8FdRPLItgnyRzb2RM+8/aeI2MgW1CzofO/2vuzitiCiEuSPSxX4hMWW/wO4C/MrNHzGzv+XBICDEd1vux/2Z3f9HMLgXwgJn9H3d/6PQnjC8KewGgDn+GKYSYJuu687v7i+P/DwH4JoCbEs/Z5+573H1P1BxCCDFdzjkazWzOzBZeewzgPQCePF+OCSE2lvV87N8J4JvjQogVgP/h7v8rGjAcDnH06PGkbQspjgkAXdbKa8ilsiooCNoyni7VDuSmqiKtxugIwIogeyyqIRlU6azPoSjoMGj9VAUZZ1WQhVcERUG5HMmPNQw+GQ6jYqcl97FFOoB5j8tyUTu0puTz2AQSbBmdj+T97HfTLc8AoGgTP9ZQwfOcg9/dnwNw3bmOF0JsLvoSLkSmKPiFyBQFvxCZouAXIlMU/EJkylQLeDZw9JAuCNmQbD8A6J5K93CLfjHY6/HCk9s7c9RWDbkkUxCJsG5FffD4/syjIp1ciorkJieZYK2CZ9M1pOgnABTk/QIAc95/bmU5LZe1gkzGSFZsutyPOvDxVC/9uqOMxGHNz49hQ2RnAFUd9C5sgv5/RMacnefFZFnV2LAH4Vnozi9Epij4hcgUBb8QmaLgFyJTFPxCZMpUV/vLosDcTDqBZ3FxkY5rV+kVzG6Pr7xuXUjX/QMACxJZojZfzpSKqDxbkHRSBivwRZAIEuQloSAJQc0wuM4Hpkg1KYp0GzUA6JFF/TJolVb3TlBbM+TKTlXzcV2WILWVJ+/U84EaNMNVgm6gBAyDpJ8+cbFvXE2pBmkFzKO2YGehO78QmaLgFyJTFPxCZIqCX4hMUfALkSkKfiEyZapSHwAY0anC9lSkrp6BSyGR/Ba2hQraKlEVJSqbFiT2eJDYE5TcQxGMM0vLh70Bb4fWDPkLiObx8PFlaus3aRnQgoQlDzTMk6f4sU4upmUvAGgT6faqyy+lY3Zf/WZqs4WofRm3IWi9VZDzcRgkmZUFqycpqU8IsQoKfiEyRcEvRKYo+IXIFAW/EJmi4BciU1aV+szsbgC/DeCQu799vG0bgK8CuBLA8wA+4O5HV9uXu2NIWiF1WjxrqyHXqGEkUdVcWonqnFnQ7siJ/lYH2XkW1CZEGcmAfFg3yLQbID2Phw7zrMmTKzw77/gJbjt8nLeTWlpmPnLfD73KfVzq8Xlsz/B53Fqnxx09wf04eOQktb31F95EbZ2dO6gNs9x/X0rPYxNInwM2j4GkeDaT3Pn/FMAtZ227A8CD7n4NgAfHfwshXkesGvzu/hCAI2dtvhXAPePH9wB433n2SwixwZzrd/6d7n5g/PhljDr2CiFeR6z7573u7sZ+swvAzPYC2AsA5RqqjAghNpZzvfMfNLNdADD+/xB7orvvc/c97r6nWENDASHExnKuwX8fgNvGj28D8K3z444QYlpMIvXdC+BdAHaY2QsAPgng0wC+ZmYfAfATAB+Y5GDujhXSdqls82yvgsgXRdCuqyISDwAMWXVJAEakMgBoW9rG/AMAj66vzqe/MC5FDQNp8alnfprcfmCR+9hd4cd65RiXvU4FGYtDkg7owac/7yxQW7kQtHML0ipPFulxPznCi232A5216fEMwuZtfNyWHduorTVPzquKn4tUMm2iFNMzWTX43f1DxPQbEx9FCHHBoV/4CZEpCn4hMkXBL0SmKPiFyBQFvxCZMtUCnu4juS8FF9+AkshDBZFxAKDf573YloPfGrGsQwAYNkSmrHj/tiaQAftDLrFF78yBIOvspZNp/4/z5DycXOHZeYd7gewV3Dsa8mvOhbmL6ZhtF/EXvSXokWcln+Oyl56Pos/PuJVACj51ivt46OAxaquDDM5mJS3d9o0XXbU6PWY4OL9ZfUKINyAKfiEyRcEvRKYo+IXIFAW/EJmi4BciU6Yq9ZkZqip9yCZoTjcg8mBUH6AfSXY1z5Yy437UpKdaP8ikivrglQU/1o9/+gq1/fClE9S2VKR9PLnEtT43nlH589fsorbdO7j8dtmOtB8tm6FjigHvx7d8gsubAM9ybEgm5kqfvy+2ws+dVpsfq9/lc7x8lMt2VZOek1abn6fDfno+rIlE8zPRnV+ITFHwC5EpCn4hMkXBL0SmKPiFyJQpr/YDFUlwGPaDzJMivRo9CFbSW2VQww98lb3V4lNSkZqBTRMkbZBadgDww+dp0WO8fIyvfHedr84vr6THzbRn6ZhfvJq3oLpsJ6+rd+lsMI9k1bkMkpkGxud+eZ4rC70uPw+6/fQqe7sKFBo+vWiCFLSm4e9ZM+SvrVWmk52KIBmoJjERtaL7mf1P/EwhxBsKBb8QmaLgFyJTFPxCZIqCX4hMUfALkSmTtOu6G8BvAzjk7m8fb/sUgN8F8Fr2ySfc/f5V9wWgRFqK6Pa41FdXaVkjSmFw49e1KpABZ2c71MZqBjpvUowjSzwh5blD3HZkmb+6ha08OeaqnbuT23du4frVFdv4aXBxi9f3awdtrYZNWha1qMZcUFevLLmtCO5hLaLb2YC361rq89c8DBKC+kM+x92gHV3f075s27aTjhmQs9+qye/nkzzzTwHckth+p7tfP/63auALIS4sVg1+d38IwJEp+CKEmCLr+c5/u5k9bmZ3mxmvxyyEuCA51+D/AoCrAVwP4ACAz7InmtleM9tvZvuHa2gfLITYWM4p+N39oLsP3b0B8EUANwXP3efue9x9T0kaOQghps85Bb+ZnV7b6f0Anjw/7gghpsUkUt+9AN4FYIeZvQDgkwDeZWbXA3AAzwP4vUkO5h6oOUFGFxviQYaYBx8yFjpbqK0TXA5ZqzEPJKpDJ7hstFJzWXG+w/e562KeafeLP5eWAXcu8GNVNT9W2/n70iH1AgGekVa1uB+Y55O/7LyuXj+QI08tpm1LfAicyNEAcGxpkR8ryO6cWeQZfzsGaWcGQZZgOZ8+ByxoYXc2qwa/u38osfmuiY8ghLgg0S/8hMgUBb8QmaLgFyJTFPxCZIqCX4hMmWoBTxgA8kOfIYKCik4ywQrezghB4cxWwY81U0fVG9PjukF2mwVtyLZ2uP+XbJ+ntt0XcalyR5We3yKQyuoet7XnuI/zs7yoppE5Odnw7M2VLs+0sxU+zgJ9doYUzmwa3nZr0PD5KGo+rtcPipMGsvTy8lJy+3yQ6eqkHR2To1Pozi9Epij4hcgUBb8QmaLgFyJTFPxCZIqCX4hMmarU5w40rIdbcBli9TGjDCZ3nqk21+ZyDSswCgANSRVc6nIZZ7HH08d2BpLdm+d5kc52i8tvXSLp+XIg9bW4vHn8RFqGAoCBcz8WyrTE2a6DN7rkPt7yxYeo7f6P/mNq85m0j/0ef896R7g8a0HZ2Jk5Po9VMMdVlQ7DIpCrjcmAkvqEEKuh4BciUxT8QmSKgl+ITFHwC5Ep003sgcPJamkRVfalCkFw7SJjRm4EK6JBslBRp6fL+nyVeqbDk19aJT9W5Xw1uhoGiUSeVhcWBzxJ5F/c+zC1/dmHaGFmHDx6lNq+/Uq6FdnLP3qBjrnv705QW8R7//gvqe0P3pFueXXnEwfpmD/6zbdR2+5Ld1FbE6gVMxVXmAqyqO9BwlVTkCSoQCH4meNO/EwhxBsKBb8QmaLgFyJTFPxCZIqCX4hMUfALkSmTtOu6HMCXAOzEqD3XPnf/vJltA/BVAFdi1LLrA+7OtR+M6ov1u2nJqd3hbZx6vbSsYWFrLS4dDgMV0FgWEYA+kfSWFk/RMW/awqW+NtN4VmFliUtA3ZX0XP3b7zx9Tsf68L3fpba3dPgcG6kleN3Vf4+OuXKe+/j8SS593vFP/z613fmNR6iN8fHvPENtX/rn/4DaZoL6fmWgLtektdkgkpDb6fNqLa1wJ7nzDwD8obtfC+CdAD5qZtcCuAPAg+5+DYAHx38LIV4nrBr87n7A3b8/frwI4GkAuwHcCuCe8dPuAfC+jXJSCHH+WdN3fjO7EsANAB4GsNPdD4xNL2P0tUAI8Tph4p/3mtk8gK8D+Ji7nzD7/98u3N2NfFk2s70A9gJaXRTiQmKieDSzGqPA/7K7f2O8+aCZ7RrbdwE4lBrr7vvcfY+777G1rEYIITaUVYPfRrf4uwA87e6fO810H4Dbxo9vA/Ct8++eEGKjmORj/68A+DCAJ8zs0fG2TwD4NICvmdlHAPwEwAdW25E7MBikNY860N+obOeR1sf3Nwxqz0XJgK067fsl2+fomDJqKRbU9/NgPnpBtheT9G5/+1vomP/25HPUFjE3x0+fppW2PfXMs3TM0YZ/NNxzBW9ftj+Q8257R1pCvucJ3hrs92+8gtpuCk65/hLPnKxmeQ0/I+dxqwr0QdKuay01/FYNfnf/W3D58DcmPpIQ4oJCa3BCZIqCX4hMUfALkSkKfiEyRcEvRKZMuYAn0BApotsN2kmRrKdhIIextmAAULf4Na9uB5LMMJ1ZdtEcb63V9HnGnwVZfcMBt/2bbz9JbYxzlfMinniVv2e/fGla/hxcxF/X9cHc/83/PT65Y6fBJL1P3/oOOubt81y6XQ5as23p8Ky+6AduQ3JeFc4zQsPitROiO78QmaLgFyJTFPxCZIqCX4hMUfALkSkKfiEyZbpSnwEl6XfnQY8xZonkvNkWz6ara26L5MOS5DdVQdnEkhRaBICi4UVL+wWXlD73T36Z2v7V//xecvvHf+s6OqYM+vh95gFeVPNf/+a11HZDk5a9Biv8fb50gd+L7nzPVmr7gz/5G2r7j+9+a3J7p8ez38o+z7asuQqIZsD9L4P7LMtajdrulWVaFrWoqu1Z6M4vRKYo+IXIFAW/EJmi4BciUxT8QmSK+Rpqfq2Xqix8vpNepfSgLl1dsWsUXw6dIaoCANz8Nl7P7pcu4+0H5tpplWCeL9ojyPVA4CIK8Pelqrha0SMrx8NgJboquCOBCeVM4AdRYk41fCW9fYq/n0snF6ktyJ3CwNKqydat/E2bK/mL7g6DDJ1BoBIE79nW2bSEcNG2WTqmmEurH7/zX7+NH7xweKI62brzC5EpCn4hMkXBL0SmKPiFyBQFvxCZouAXIlNWTewxs8sBfAmjFtwOYJ+7f97MPgXgdwG8Mn7qJ9z9/mhf7k4TZ8qCS1tdUjetbHFFw9NNg0fjKq6/lUGxtZKoNS3SmgoAZoN6gc2AJxFVVN4EyiBpqUP0wzrQFdtBolMZJIp4w+e4bqXlqxPHD9Mxgxkulc2AZ9T0OnxcayY9rhNomL1TvJVXHdRdjOajE8iHndl0Dchqhkt9YOfcGrrhTpLVNwDwh+7+fTNbAPCImT0wtt3p7n808dGEEBcMk/TqOwDgwPjxopk9DWD3RjsmhNhY1vSd38yuBHADgIfHm243s8fN7G4zu/g8+yaE2EAmDn4zmwfwdQAfc/cTAL4A4GoA12P0yeCzZNxeM9tvZvun+EtiIcQqTBT8ZlZjFPhfdvdvAIC7H3T3obs3AL4I4KbUWHff5+573H3PGtYihBAbzKrBb2YG4C4AT7v7507bvuu0p70fwNrbyAghNo1JVvt/BcCHATxhZo+Ot30CwIfM7HqM5L/nAfzeqgcrS1x60Zak7eixY3QcS0gz5+2dioa/tLrN22u1ar5PkpCIMsguHPb5d52i4B+Fiorb2oG02JpN1wxst4PUQ+cZlR7UNLRATu0NTya3d+a4rDhoB+2u2vxYc+DjWG3IpeNp/wDAinOr8ejBR9u6FbTeaqX9HwYtuc7Hp+hJVvv/FkhWqAw1fSHEhY1+4SdEpij4hcgUBb8QmaLgFyJTFPxCZMpU23XNdjq47q1vS9oefeoxOu74cjpry8ElqvYMl+zqkuskg6DAJEvC8yADb+h8iqsg064IZJ6ogGdBZEdHkEFYB/eAqMpooDc1LHvTgzZq3UD6DH4e2u3ydmPDQXo+Ikm3F7Ty6vb5OTcXSMidDpdaq5pIlVFhVSaLBvLxzzx14mcKId5QKPiFyBQFvxCZouAXIlMU/EJkioJfiEyZqtS30DL8o6vSUs8Nl91Ixz32/KvJ7c+8cISO6fe4/FMHMlodFPcsSBYbSRwb2YJjNUFxTKv4W9MEhSJbZVrCqqKipYGc54HcFGWx0Ry24H1ZXkkXagWAXj/IpgvkQ1YXtgp87wZZjpFUWQUScuNRNmB6ex1kYvbZSbeGijm68wuRKQp+ITJFwS9Epij4hcgUBb8QmaLgFyJTpir1FQDmSWHNesgllJuvTjcIumL7DjrmoSd4MeEqkNiaYVDMsklnbUUyTnR5dYvkKz6uKnj2WEkUoKLhMpSVfH/GqpYC6Dt/ccukgKct89c8jF5zsozkiEEwWTQDMpBSDx87QW2tmstvUUHToJ4sBqxYa9Q3siJianBun43u/EJkioJfiExR8AuRKQp+ITJFwS9Epqy62m9mHQAPYZSrUQH4C3f/pJldBeArALYDeATAh92dZ20AWFru4dEn/y5pu/qKS+i4mSK9wrqj5ivz8yVXDwITLFhhHRAlwIPWWh6ssntQK67keTgA+DT3mP+BH9FK+pAVLgRQdwInl9NJOsOg3l60UF23ozZqkRKQlj8OvHSY76+epbah8Syu5RV+Pq6cPEptCyfT42yBtxQryfs86PEalGczyZ2/C+DX3f06jNpx32Jm7wTwGQB3uvvPAzgK4CMTH1UIsemsGvw+4rVLUD3+5wB+HcBfjLffA+B9G+KhEGJDmOg7v5mV4w69hwA8AODHAI65+2uf7V4AkP4ljhDigmSi4Hf3obtfD+AyADcB+IVJD2Bme81sv5ntXw6+PwohpsuaVvvd/RiAvwbwDwFsNbPXFgwvA/AiGbPP3fe4+56ZoNmEEGK6rBr8ZnaJmW0dP54B8G4AT2N0Efhn46fdBuBbG+WkEOL8M0lizy4A95hZidHF4mvu/m0z+wGAr5jZfwLwvwHctdqOWq0ab7riTUnbcMjlmqVTaXmoDiSZhVmegBEoW/AikAgDGZAeyrj0UgbZHsMVfl0OulrRfJWy4DJUEchvZUGr8aHpLlNbG2kZ0FtBohB3Ef2ght+g5HN16KVD6f2tBPUHAwmzwQq1HTnO3+vhCp+rV08cS26fa2+lY9qdtP/DHq+DeDarBr+7Pw7ghsT25zD6/i+EeB2iX/gJkSkKfiEyRcEvRKYo+IXIFAW/EJlivob2Pus+mNkrAH4y/nMHAJ5aNT3kx5nIjzN5vfnxZnfnKbKnMdXgP+PAZvvdfc+mHFx+yA/5oY/9QuSKgl+ITNnM4N+3icc+HflxJvLjTN6wfmzad34hxOaij/1CZMqmBL+Z3WJmz5jZs2Z2x2b4MPbjeTN7wsweNbP9Uzzu3WZ2yMyePG3bNjN7wMx+NP7/4k3y41Nm9uJ4Th41s/dOwY/LzeyvzewHZvaUmf3+ePtU5yTwY6pzYmYdM/uumT029uM/jLdfZWYPj+Pmq2bGUyQnwd2n+g9AiVEZsLcAaAF4DMC10/Zj7MvzAHZswnF/FcCNAJ48bdt/AXDH+PEdAD6zSX58CsDHpzwfuwDcOH68AOCHAK6d9pwEfkx1TjBKOp8fP64BPAzgnQC+BuCD4+3/HcC/XM9xNuPOfxOAZ939OR+V+v4KgFs3wY9Nw90fAnDkrM23YlQIFZhSQVTix9Rx9wPu/v3x40WMisXsxpTnJPBjqviIDS+auxnBvxvAT0/7ezOLfzqAvzKzR8xs7yb58Bo73f3A+PHLAHZuoi+3m9nj468FG/7143TM7EqM6kc8jE2ck7P8AKY8J9Mompv7gt/N7n4jgN8C8FEz+9XNdggYXfkxujBtBl8AcDVGPRoOAPjstA5sZvMAvg7gY+5+Rp/sac5Jwo+pz4mvo2jupGxG8L8I4PLT/qbFPzcad39x/P8hAN/E5lYmOmhmuwBg/H+6/tQG4+4HxydeA+CLmNKcmFmNUcB92d2/Md489TlJ+bFZczI+9pqL5k7KZgT/9wBcM165bAH4IID7pu2Emc2Z2cJrjwG8B8CT8agN5T6MCqECm1gQ9bVgG/N+TGFObNQj7S4AT7v7504zTXVOmB/TnpOpFc2d1grmWauZ78VoJfXHAP7dJvnwFoyUhscAPDVNPwDci9HHxz5G390+glHPwwcB/AjAdwBs2yQ//gzAEwAexyj4dk3Bj5sx+kj/OIBHx//eO+05CfyY6pwA+CWMiuI+jtGF5t+fds5+F8CzAP4cQHs9x9Ev/ITIlNwX/ITIFgW/EJmi4BciUxT8QmSKgl+ITFHwC5EpCn4hMkXBL0Sm/D+82HUWM4FhzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from generator import ImageFaceLandmarkDataGenerator\n",
    "from muct import MUCT\n",
    "\n",
    "batch_size = 1\n",
    "input_shape = (32, 32, 3)\n",
    "topic = 'left_eye_12'\n",
    "output_size = int(topic.split('_')[-1])\n",
    "\n",
    "test_generator = ImageFaceLandmarkDataGenerator(rotate_bounding_box_part='face',\n",
    "                                                rotate_limit_in_degrees=10,\n",
    "                                                scale_bounding_box_part='face',\n",
    "                                                scale_bounding_box_size=64,\n",
    "                                                scale_limit_ratio=0.1,\n",
    "                                                translate_x_ratio=0.2,\n",
    "                                                translate_y_ratio=0.3,\n",
    "                                                target_bounding_box_part='left_eye',\n",
    "                                                random_horizontal_flip=True)\n",
    "\n",
    "for X, y in test_generator.flow(face_landmarks_final['train'], MUCT[topic], (32, 32), batch_size):\n",
    "    bgr_image = X[0]\n",
    "    landmarks = y[0]\n",
    "    print(len(landmarks))\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "    for i in range(0, len(landmarks), 2):\n",
    "        cv2.circle(rgb_image, (int(landmarks[i]), int(landmarks[i+1])), 1, (255), -1)\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
